{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9879ef36",
   "metadata": {
    "papermill": {
     "duration": 0.00658,
     "end_time": "2025-12-01T00:22:27.253467",
     "exception": false,
     "start_time": "2025-12-01T00:22:27.246887",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfa42d86",
   "metadata": {
    "papermill": {
     "duration": 0.005231,
     "end_time": "2025-12-01T00:22:27.264300",
     "exception": false,
     "start_time": "2025-12-01T00:22:27.259069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **AI Opportunity Navigator ‚Äî Capstone Project**\n",
    "A multi-agent assistant that reads your background, finds relevant opportunities, and gives you a clear plan for what to do next.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 1. Introduction\n",
    "\n",
    "Career decisions are messy ‚Äî too many options, not enough clarity.\n",
    "\n",
    "While going through the Google √ó Kaggle AI Agents Intensive, I realized that the same multi-agent ideas we practiced can actually be used to solve this problem in real life.\n",
    "\n",
    "So I built **AI Opportunity Navigator**, a personalized multi-agent system that looks at a student's or job seeker's background and suggests:\n",
    "\n",
    "- what roles or opportunities match them  \n",
    "- why they match  \n",
    "- what steps they should take next  \n",
    "\n",
    "The goal is simple: **reduce confusion and give direction.**\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 2. What Problem This Agent Solves\n",
    "\n",
    "Many people (including me) run into:\n",
    "\n",
    "- Too many choices and not enough clarity  \n",
    "- Not knowing which roles match their skills  \n",
    "- Confusion about which professors / labs / competitions fit their interests  \n",
    "- Being unsure whether to apply, learn more, or switch direction  \n",
    "- Generic career tools that don‚Äôt really adapt to their background  \n",
    "\n",
    "I wanted something that actually **understands your profile and reacts to it**, instead of giving template advice.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 3. High-Level Idea\n",
    "\n",
    "The AI Opportunity Navigator:\n",
    "\n",
    "- reads a short background from the user  \n",
    "- extracts skills, interests, and goals  \n",
    "- searches or generates matched opportunities  \n",
    "- scores them  \n",
    "- creates a simple action plan with ‚Äúdo this next‚Äù steps  \n",
    "\n",
    "Under the hood, it uses multiple agents working together:\n",
    "\n",
    "- **Profile Agent** ‚Äì understands the user  \n",
    "- **Opportunity Finder Agent** ‚Äì proposes possible paths  \n",
    "- **Scoring Agent** ‚Äì ranks options  \n",
    "- **Planner Agent** ‚Äì turns everything into a clear next-step plan  \n",
    "- **Orchestrator** ‚Äì coordinates the workflow\n",
    "\n",
    "Next, we‚Äôll define the tools and agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdc365c",
   "metadata": {
    "papermill": {
     "duration": 0.005087,
     "end_time": "2025-12-01T00:22:27.274581",
     "exception": false,
     "start_time": "2025-12-01T00:22:27.269494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üîπ 4. Agent Architecture (How It Actually Works)\n",
    "\n",
    "Instead of one giant ‚Äúdo everything‚Äù agent, I split the logic into small, focused agents:\n",
    "\n",
    "1. **Profile Agent**  \n",
    "   - Reads the user‚Äôs background: education, projects, skills, goals  \n",
    "   - Extracts a clean JSON-style profile with:\n",
    "     - `skills`\n",
    "     - `interests`\n",
    "     - `experience`\n",
    "     - `goals`\n",
    "   - This becomes the shared context for the other agents.\n",
    "\n",
    "2. **Opportunity Finder Agent**  \n",
    "   - Uses the profile to brainstorm possible directions:\n",
    "     - roles (e.g., ‚ÄúML Engineer intern‚Äù, ‚ÄúCloud Support‚Äù)\n",
    "     - learning paths (courses, topics)\n",
    "     - projects or competitions\n",
    "   - It doesn‚Äôt just throw random ideas ‚Äî it tries to match skills and interests.\n",
    "\n",
    "3. **Scoring Agent**  \n",
    "   - Looks at each opportunity and scores it on:\n",
    "     - skill match (how well it fits the current profile)\n",
    "     - difficulty level\n",
    "     - relevance to long-term goals  \n",
    "   - Returns a short justification for each score.\n",
    "\n",
    "4. **Planner Agent**  \n",
    "   - Takes the top opportunities and converts them into a simple, clear plan:\n",
    "     - what to focus on now\n",
    "     - what to apply for\n",
    "     - what to learn or build next\n",
    "   - Output is a human-readable roadmap.\n",
    "\n",
    "5. **Orchestrator (Multi-Agent Workflow)**  \n",
    "   - Controls the overall flow:\n",
    "     1. Run **Profile Agent** on the user‚Äôs background  \n",
    "     2. Pass its output to **Opportunity Finder Agent**  \n",
    "     3. Pass opportunities + profile to **Scoring Agent**  \n",
    "     4. Pass best options to **Planner Agent**  \n",
    "   - Implemented using a **sequential multi-agent workflow**, similar to the course notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a7a00",
   "metadata": {
    "papermill": {
     "duration": 0.005046,
     "end_time": "2025-12-01T00:22:27.284944",
     "exception": false,
     "start_time": "2025-12-01T00:22:27.279898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017fe77e",
   "metadata": {
    "papermill": {
     "duration": 0.005156,
     "end_time": "2025-12-01T00:22:27.295240",
     "exception": false,
     "start_time": "2025-12-01T00:22:27.290084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44105526",
   "metadata": {
    "papermill": {
     "duration": 0.004986,
     "end_time": "2025-12-01T00:22:27.305555",
     "exception": false,
     "start_time": "2025-12-01T00:22:27.300569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "## üîß Step 1 ‚Äî Setup, Imports, and Authentication\n",
    "\n",
    "This section initializes everything needed for the project:\n",
    "\n",
    "- Imports Google ADK components  \n",
    "- Imports Gemini function-calling tools  \n",
    "- Sets up the session and runner  \n",
    "- Loads the **Google API Key** securely using Kaggle Secrets  \n",
    "\n",
    "If you're running this notebook on Kaggle:\n",
    "\n",
    "1. Go to **Settings ‚Üí Secrets**  \n",
    "2. Create a new secret named **`GOOGLE_API_KEY`**  \n",
    "3. Paste your Gemini API key  \n",
    "\n",
    "Once this is done, the code below will automatically authenticate and prepare the environment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00eb11b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:22:27.317806Z",
     "iopub.status.busy": "2025-12-01T00:22:27.317130Z",
     "iopub.status.idle": "2025-12-01T00:23:24.427303Z",
     "shell.execute_reply": "2025-12-01T00:23:24.426192Z"
    },
    "papermill": {
     "duration": 57.122723,
     "end_time": "2025-12-01T00:23:24.433517",
     "exception": false,
     "start_time": "2025-12-01T00:22:27.310794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup and authentication complete.\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 1: Imports + auth =====\n",
    "import os\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from google.genai import types\n",
    "from google.genai.types import Part, UserContent\n",
    "\n",
    "from google.adk.agents import LlmAgent, SequentialAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools.function_tool import FunctionTool\n",
    "\n",
    "# Get GOOGLE_API_KEY from Kaggle secrets\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    print(\"‚úÖ Setup and authentication complete.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå ERROR: Add 'GOOGLE_API_KEY' to Kaggle Secrets first.\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44923c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:24.446678Z",
     "iopub.status.busy": "2025-12-01T00:23:24.445433Z",
     "iopub.status.idle": "2025-12-01T00:23:24.452175Z",
     "shell.execute_reply": "2025-12-01T00:23:24.451239Z"
    },
    "papermill": {
     "duration": 0.014858,
     "end_time": "2025-12-01T00:23:24.453744",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.438886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retry config ready.\n"
     ]
    }
   ],
   "source": [
    "# ===== Retry options for the model =====\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,\n",
    "    exp_base=2,\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 502, 503],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Retry config ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a143a7e",
   "metadata": {
    "papermill": {
     "duration": 0.005327,
     "end_time": "2025-12-01T00:23:24.464839",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.459512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### üîß Step 2 ‚Äî Define Core Tools\n",
    "These Python functions extract the user profile, generate opportunity ideas, and score them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152c7484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:24.477820Z",
     "iopub.status.busy": "2025-12-01T00:23:24.477108Z",
     "iopub.status.idle": "2025-12-01T00:23:24.495281Z",
     "shell.execute_reply": "2025-12-01T00:23:24.494180Z"
    },
    "papermill": {
     "duration": 0.026556,
     "end_time": "2025-12-01T00:23:24.496766",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.470210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Python tools defined.\n"
     ]
    }
   ],
   "source": [
    "# ===== Core Python tools =====\n",
    "\n",
    "def extract_profile(profile_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Take a free-form profile text and return a structured profile.\n",
    "    Works well with text like:\n",
    "    Background: ...\n",
    "    Skills: ...\n",
    "    Interests: ...\n",
    "    Goals: ...\n",
    "    \"\"\"\n",
    "    lines = profile_text.splitlines()\n",
    "    profile = {\n",
    "        \"raw_text\": profile_text,\n",
    "        \"background\": \"\",\n",
    "        \"skills\": [],\n",
    "        \"interests\": [],\n",
    "        \"goals\": [],\n",
    "    }\n",
    "\n",
    "    current_key = None\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        lower = line.lower()\n",
    "\n",
    "        if lower.startswith(\"background:\"):\n",
    "            current_key = \"background\"\n",
    "            profile[\"background\"] = line.split(\":\", 1)[1].strip()\n",
    "        elif lower.startswith(\"skills:\"):\n",
    "            current_key = \"skills\"\n",
    "            skills_str = line.split(\":\", 1)[1].strip()\n",
    "            profile[\"skills\"] = [s.strip() for s in skills_str.split(\",\") if s.strip()]\n",
    "        elif lower.startswith(\"interests:\"):\n",
    "            current_key = \"interests\"\n",
    "            int_str = line.split(\":\", 1)[1].strip()\n",
    "            profile[\"interests\"] = [s.strip() for s in int_str.split(\",\") if s.strip()]\n",
    "        elif lower.startswith(\"goals:\"):\n",
    "            current_key = \"goals\"\n",
    "            goals_str = line.split(\":\", 1)[1].strip()\n",
    "            profile[\"goals\"] = [s.strip() for s in goals_str.split(\",\") if s.strip()]\n",
    "        else:\n",
    "            # continuation lines ‚Äì append to the last section if exists\n",
    "            if current_key == \"background\" and line:\n",
    "                profile[\"background\"] += \" \" + line\n",
    "\n",
    "    return profile\n",
    "\n",
    "\n",
    "def suggest_opportunities(profile: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Very simple rule-based suggestion engine.\n",
    "    Returns a dict with profile + list of opportunity dicts.\n",
    "    \"\"\"\n",
    "    skills = [s.lower() for s in profile.get(\"skills\", [])]\n",
    "    interests = [i.lower() for i in profile.get(\"interests\", [])]\n",
    "    goals = [g.lower() for g in profile.get(\"goals\", [])]\n",
    "\n",
    "    opps = []\n",
    "\n",
    "    # Research assistant\n",
    "    if \"research\" in \" \".join(interests + goals):\n",
    "        opps.append({\n",
    "            \"type\": \"research\",\n",
    "            \"title\": \"Graduate Research Assistant ‚Äî AI / ML\",\n",
    "            \"reason\": \"You mentioned interest in research and AI/ML.\",\n",
    "        })\n",
    "\n",
    "    # Cloud + AI internship\n",
    "    if \"cloud\" in \" \".join(skills + interests + goals):\n",
    "        opps.append({\n",
    "            \"type\": \"internship\",\n",
    "            \"title\": \"Cloud + AI Engineering Internship\",\n",
    "            \"reason\": \"You have cloud + AI related skills and goals.\",\n",
    "        })\n",
    "\n",
    "    # Agentic AI projects\n",
    "    if \"agent\" in \" \".join(interests + goals) or \"agents\" in \" \".join(interests + goals):\n",
    "        opps.append({\n",
    "            \"type\": \"project\",\n",
    "            \"title\": \"Applied ML + Agentic AI Project\",\n",
    "            \"reason\": \"You‚Äôre interested in building agentic AI systems.\",\n",
    "        })\n",
    "\n",
    "    # Fallback\n",
    "    if not opps:\n",
    "        opps.append({\n",
    "            \"type\": \"learning\",\n",
    "            \"title\": \"Structured 90-day learning plan\",\n",
    "            \"reason\": \"No specific interests detected, so start with a broad ML/AI roadmap.\",\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"profile\": profile,\n",
    "        \"opportunities\": opps,\n",
    "    }\n",
    "\n",
    "\n",
    "def score_opportunities(profile_with_opps: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Add a simple 'match_score' to each opportunity and sort them.\n",
    "    \"\"\"\n",
    "    profile = profile_with_opps.get(\"profile\", {})\n",
    "    skills = {s.lower() for s in profile.get(\"skills\", [])}\n",
    "    interests = {i.lower() for i in profile.get(\"interests\", [])}\n",
    "    goals = {g.lower() for g in profile.get(\"goals\", [])}\n",
    "\n",
    "    for opp in profile_with_opps.get(\"opportunities\", []):\n",
    "        text = (opp.get(\"title\", \"\") + \" \" + opp.get(\"reason\", \"\")).lower()\n",
    "        score = 0\n",
    "\n",
    "        # basic scoring\n",
    "        for w in skills:\n",
    "            if w and w in text:\n",
    "                score += 2\n",
    "        for w in interests:\n",
    "            if w and w in text:\n",
    "                score += 1\n",
    "        for w in goals:\n",
    "            if w and w in text:\n",
    "                score += 2\n",
    "\n",
    "        opp[\"match_score\"] = score\n",
    "\n",
    "    # sort by score desc\n",
    "    profile_with_opps[\"opportunities\"] = sorted(\n",
    "        profile_with_opps.get(\"opportunities\", []),\n",
    "        key=lambda o: o.get(\"match_score\", 0),\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    return profile_with_opps\n",
    "\n",
    "print(\"‚úÖ Python tools defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90aeb1",
   "metadata": {
    "papermill": {
     "duration": 0.00539,
     "end_time": "2025-12-01T00:23:24.507772",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.502382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### üß∞ Step 4 ‚Äî Convert Python Functions into ADK Tools\n",
    "These tools allow the agents to call our Python functions during the workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a78e3368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:24.520497Z",
     "iopub.status.busy": "2025-12-01T00:23:24.520213Z",
     "iopub.status.idle": "2025-12-01T00:23:24.526083Z",
     "shell.execute_reply": "2025-12-01T00:23:24.524942Z"
    },
    "papermill": {
     "duration": 0.01445,
     "end_time": "2025-12-01T00:23:24.527614",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.513164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Function tools created (simple ADK version).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Cell 4: Wrap Python functions as ADK tools (simple version) =====\n",
    "\n",
    "from google.adk.tools.function_tool import FunctionTool\n",
    "\n",
    "profile_tool = FunctionTool(extract_profile)\n",
    "opportunity_tool = FunctionTool(suggest_opportunities)\n",
    "scoring_tool = FunctionTool(score_opportunities)\n",
    "\n",
    "print(\"‚úÖ Function tools created (simple ADK version).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ff6a7",
   "metadata": {
    "papermill": {
     "duration": 0.005476,
     "end_time": "2025-12-01T00:23:24.538819",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.533343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### üß† Step 5 ‚Äî Define the LLM Agents & Build the Orchestrator\n",
    "This step sets up the core multi-agent workflow.  \n",
    "Each agent has a clear responsibility:\n",
    "\n",
    "- **ProfileAgent** ‚Üí Understands the user background  \n",
    "- **OpportunityAgent** ‚Üí Suggests relevant roles, projects, and learning paths  \n",
    "- **PlannerAgent** ‚Üí Scores options and creates a structured 60‚Äì90 day plan  \n",
    "\n",
    "These agents are then connected using a **SequentialAgent orchestration flow**, so the output of one becomes the input of the next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d902ce3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:24.551595Z",
     "iopub.status.busy": "2025-12-01T00:23:24.551282Z",
     "iopub.status.idle": "2025-12-01T00:23:24.558604Z",
     "shell.execute_reply": "2025-12-01T00:23:24.557501Z"
    },
    "papermill": {
     "duration": 0.015922,
     "end_time": "2025-12-01T00:23:24.560161",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.544239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agents and orchestrator created.\n"
     ]
    }
   ],
   "source": [
    "# ===== Define LLM agents + Sequential orchestrator (no retry_options) =====\n",
    "\n",
    "# ProfileAgent ‚Äì understands the user background\n",
    "profile_agent = LlmAgent(\n",
    "    name=\"profile_agent\",\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    tools=[profile_tool],\n",
    "    instruction=(\n",
    "        \"You are ProfileAgent. Read the user's background, skills, \"\n",
    "        \"interests, and goals from free-form text. \"\n",
    "        \"Call the extract_profile tool to structure it into a profile \"\n",
    "        \"dictionary. Then briefly summarize who this person is.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# OpportunityAgent ‚Äì suggests options\n",
    "opportunity_agent = LlmAgent(\n",
    "    name=\"opportunity_agent\",\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    tools=[opportunity_tool],\n",
    "    instruction=(\n",
    "        \"You are OpportunityAgent. Given a structured profile, \"\n",
    "        \"call suggest_opportunities to propose research roles, internships, \"\n",
    "        \"projects, and learning paths that fit this person. \"\n",
    "        'Explain in 2‚Äì3 sentences why they match. '\n",
    "        \"Always keep the tone practical and encouraging.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# PlannerAgent ‚Äì turns options into a concrete plan\n",
    "planner_agent = LlmAgent(\n",
    "    name=\"planner_agent\",\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    tools=[scoring_tool],\n",
    "    instruction=(\n",
    "        \"You are PlannerAgent. Take the profile plus list of opportunities, \"\n",
    "        \"call score_opportunities, then create a clear 60‚Äì90 day action plan. \"\n",
    "        \"First list the top 3 opportunities with reasons. Then give a weekly \"\n",
    "        \"plan grouped by Month 1 / Month 2 / Month 3.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Orchestrator ‚Äì runs everything in order\n",
    "orchestrator = SequentialAgent(\n",
    "    name=\"ai_opportunity_navigator\",\n",
    "    sub_agents=[profile_agent, opportunity_agent, planner_agent],\n",
    "    description=(\n",
    "        \"Runs profile understanding, opportunity suggestion, and 60‚Äì90 day \"\n",
    "        \"planning in sequence to guide the user on research, internships, \"\n",
    "        \"and projects.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agents and orchestrator created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eff34e",
   "metadata": {
    "papermill": {
     "duration": 0.005604,
     "end_time": "2025-12-01T00:23:24.571473",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.565869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ‚öôÔ∏è Step 6 ‚Äî Create the Runner & Session\n",
    "Now that all agents and the orchestrator are ready, we initialize the **InMemoryRunner**, which is responsible for executing the multi-agent pipeline.\n",
    "\n",
    "We also create a **session**, which allows the agents to maintain context across multiple turns.  \n",
    "This is important because our system will support follow-up questions and multi-step interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81924050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:24.584537Z",
     "iopub.status.busy": "2025-12-01T00:23:24.583807Z",
     "iopub.status.idle": "2025-12-01T00:23:24.590745Z",
     "shell.execute_reply": "2025-12-01T00:23:24.589817Z"
    },
    "papermill": {
     "duration": 0.0152,
     "end_time": "2025-12-01T00:23:24.592209",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.577009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Runner and session ready.\n",
      "Session ID: 933b1230-c58c-4bbd-8f47-8de13e6022c8\n"
     ]
    }
   ],
   "source": [
    "# ===== Create InMemoryRunner + session =====\n",
    "\n",
    "runner = InMemoryRunner(agent=orchestrator)\n",
    "\n",
    "async def _create_session():\n",
    "    return await runner.session_service.create_session(\n",
    "        app_name=runner.app_name,\n",
    "        user_id=\"demo_user\",\n",
    "    )\n",
    "\n",
    "session = await _create_session()  # works in Kaggle notebooks\n",
    "print(\"‚úÖ Runner and session ready.\")\n",
    "print(\"Session ID:\", session.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b6121",
   "metadata": {
    "papermill": {
     "duration": 0.005746,
     "end_time": "2025-12-01T00:23:24.603722",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.597976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### üß™ Step 7 ‚Äî Test the Multi-Agent Pipeline\n",
    "Before integrating everything into a UI, we test the entire workflow by sending a sample profile into the system.\n",
    "\n",
    "This runs the full sequence:\n",
    "1Ô∏è‚É£ ProfileAgent ‚Üí extracts structured profile  \n",
    "2Ô∏è‚É£ OpportunityAgent ‚Üí suggests relevant roles & paths  \n",
    "3Ô∏è‚É£ PlannerAgent ‚Üí generates a 60‚Äì90 day plan  \n",
    "\n",
    "The output printed below confirms that all agents are working together correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e37bb9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:24.616432Z",
     "iopub.status.busy": "2025-12-01T00:23:24.616114Z",
     "iopub.status.idle": "2025-12-01T00:23:35.120375Z",
     "shell.execute_reply": "2025-12-01T00:23:35.119214Z"
    },
    "papermill": {
     "duration": 10.513202,
     "end_time": "2025-12-01T00:23:35.122491",
     "exception": false,
     "start_time": "2025-12-01T00:23:24.609289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Running AI Opportunity Navigator on your profile...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This individual has a Master's degree in Computer Science with a specialization in AI, cloud, and distributed systems. They are proficient in Python, machine learning, deep learning, PyTorch, cloud computing, networking, and Git. Their interests lie in AI agents, research, Kaggle competitions, and cloud/AI projects. Their goals are to develop robust AI agent projects, secure a research or internship position, and advance into an AI/ML engineering role. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've found a few opportunities that seem like a great fit for your background and goals. A Graduate Research Assistant role focusing on AI/ML would align well with your interest in research and your advanced studies. Additionally, a Cloud + AI Engineering Internship would leverage your existing cloud computing skills and your goal of working with AI. Finally, an Applied ML + Agentic AI Project would be a perfect way to build on your interest in AI agents and develop strong project experience. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 3 opportunities based on your profile:\n",
      "\n",
      "1.  **Graduate Research Assistant ‚Äî AI / ML**: This role aligns perfectly with your interest in research and your advanced studies in AI/ML.\n",
      "2.  **Cloud + AI Engineering Internship**: This internship will allow you to leverage your existing skills in cloud computing and your goal of working with AI technologies.\n",
      "3.  **Applied ML + Agentic AI Project**: This project is an excellent opportunity to deepen your experience with AI agents and build a strong portfolio of agentic AI systems.\n",
      "\n",
      "Here is a 60-90 day action plan:\n",
      "\n",
      "**Month 1: Foundation and Exploration**\n",
      "\n",
      "*   **Week 1-2**:\n",
      "    *   **Research Assistant**: Identify potential PIs and labs at Wright State University or other institutions whose research aligns with your AI/ML interests. Review their publications and ongoing projects.\n",
      "    *   **Internship**: Begin researching companies that offer Cloud + AI internships. Update your resume and LinkedIn profile to highlight relevant skills and projects.\n",
      "    *   **Project**: Define the scope and objectives for your agentic AI project. Start by outlining the core functionalities and the AI techniques you plan to use.\n",
      "*   **Week 3-4**:\n",
      "    *   **Research Assistant**: Reach out to professors or PIs with a tailored email expressing your interest in their research and inquire about potential RA positions. Attach your CV.\n",
      "    *   **Internship**: Start applying to Cloud + AI internship positions. Network with professionals in the field through LinkedIn or university career services.\n",
      "    *   **Project**: Set up your development environment for the agentic AI project. Begin implementing a basic version or prototype of your agent.\n",
      "\n",
      "**Month 2: Skill Development and Application**\n",
      "\n",
      "*   **Week 5-6**:\n",
      "    *   **Research Assistant**: Follow up on your initial inquiries. If possible, schedule informational interviews to learn more about the research environment and expectations.\n",
      "    *   **Internship**: Continue applying for internships and preparing for interviews. Practice coding challenges and behavioral questions.\n",
      "    *   **Project**: Develop a more advanced feature of your agentic AI project. Focus on integrating more complex AI models or algorithms.\n",
      "*   **Week 7-8**:\n",
      "    *   **Research Assistant**: Actively participate in any research group meetings or seminars you get access to. Demonstrate your enthusiasm and technical understanding.\n",
      "    *   **Internship**: Aim to secure at least one or two interviews for internships.\n",
      "    *   **Project**: Document your progress on the agentic AI project. Consider creating a GitHub repository to showcase your work.\n",
      "\n",
      "**Month 3: Intensification and Outcomes**\n",
      "\n",
      "*   **Week 9-10**:\n",
      "    *   **Research Assistant**: If you've received offers or promising leads, focus on negotiating terms and preparing for the role. If not, refine your search and outreach strategy.\n",
      "    *   **Internship**: Continue with internship interviews. If you have offers, evaluate them based on your career goals.\n",
      "    *   **Project**: Work towards completing a significant milestone or the Minimum Viable Product (MVP) of your agentic AI project.\n",
      "*   **Week 11-12**:\n",
      "    *   **Research Assistant**: Ideally, you will be settling into a research assistant role or have a clear path forward.\n",
      "    *   **Internship**: Aim to accept an internship offer.\n",
      "    *   **Project**: Finalize your agentic AI project. Prepare a demo or presentation of your work, highlighting the AI techniques and their effectiveness.\n",
      "*   **Week 13 (Buffer/Continuation)**:\n",
      "    *   Continue to refine your project, seek feedback, and prepare for the next steps in your career.\n",
      "    *   If you've secured a role or internship, focus on excelling in it. If not, reassess your strategy and continue applying. \n",
      "\n",
      "\n",
      "‚úÖ Done.\n"
     ]
    }
   ],
   "source": [
    "# ===== Test the multi-agent pipeline =====\n",
    "\n",
    "test_profile_text = \"\"\"\n",
    "Background: MS in Computer Science at Wright State University, focusing on AI, cloud, and distributed systems.\n",
    "Skills: Python, machine learning, deep learning, PyTorch, cloud computing, networking, Git.\n",
    "Interests: AI agents, research assistant roles, Kaggle competitions, cloud + AI projects.\n",
    "Goals: Build strong agentic AI projects, get a research/internship role, and move towards AI/ML engineering.\n",
    "\"\"\"\n",
    "\n",
    "content = UserContent(parts=[Part(text=test_profile_text)])\n",
    "\n",
    "print(\"### Running AI Opportunity Navigator on your profile...\\n\")\n",
    "\n",
    "final_text = \"\"\n",
    "\n",
    "\n",
    "for event in runner.run(\n",
    "    user_id=session.user_id,\n",
    "    session_id=session.id,\n",
    "    new_message=content,\n",
    "):\n",
    "    if getattr(event, \"content\", None):\n",
    "        for p in event.content.parts or []:\n",
    "            if getattr(p, \"text\", None):\n",
    "                print(p.text, \"\\n\")\n",
    "                final_text += p.text + \"\\n\\n\"\n",
    "\n",
    "print(\"\\n‚úÖ Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b817b68",
   "metadata": {
    "papermill": {
     "duration": 0.006315,
     "end_time": "2025-12-01T00:23:35.135332",
     "exception": false,
     "start_time": "2025-12-01T00:23:35.129017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### üß± Step 8 ‚Äî UI Helper (Convert Form Inputs into Profile Text)\n",
    "\n",
    "To prepare the user data for the multi-agent pipeline, we convert all the UI form inputs  \n",
    "(name, background, skills, interests, goals, etc.) into a structured text block.\n",
    "\n",
    "This formatted profile text is what gets passed into the SequentialAgent workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cbdf67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:35.149565Z",
     "iopub.status.busy": "2025-12-01T00:23:35.149210Z",
     "iopub.status.idle": "2025-12-01T00:23:39.468630Z",
     "shell.execute_reply": "2025-12-01T00:23:39.467641Z"
    },
    "papermill": {
     "duration": 4.328754,
     "end_time": "2025-12-01T00:23:39.470343",
     "exception": false,
     "start_time": "2025-12-01T00:23:35.141589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===== UI Helper: build profile text from form inputs =====\n",
    "\n",
    "from google.genai.types import Part, UserContent\n",
    "import gradio as gr\n",
    "\n",
    "def build_profile_text_ui(\n",
    "    name,\n",
    "    background,\n",
    "    skills,\n",
    "    interests,\n",
    "    goals,\n",
    "    graduated,\n",
    "    role_types,\n",
    "    exp_level,\n",
    "):\n",
    "    name = (name or \"\").strip() or \"User\"\n",
    "    background = (background or \"\").strip()\n",
    "    skills = (skills or \"\").strip()\n",
    "    interests = (interests or \"\").strip()\n",
    "    goals = (goals or \"\").strip()\n",
    "\n",
    "    grad_status = \"Yes\" if graduated else \"No\"\n",
    "    role_types = \", \".join(role_types or []) if role_types else \"Not specified\"\n",
    "\n",
    "    lines = [\n",
    "        f\"Name: {name}\",\n",
    "        f\"Graduation completed: {grad_status}\",\n",
    "        f\"Experience level: {exp_level or 'Not specified'}\",\n",
    "        f\"Target roles: {role_types}\",\n",
    "        \"\",\n",
    "        f\"Background: {background or 'Not provided'}\",\n",
    "        f\"Skills: {skills or 'Not provided'}\",\n",
    "        f\"Interests: {interests or 'Not provided'}\",\n",
    "        f\"Goals: {goals or 'Not provided'}\",\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb831d11",
   "metadata": {
    "papermill": {
     "duration": 0.006282,
     "end_time": "2025-12-01T00:23:39.483014",
     "exception": false,
     "start_time": "2025-12-01T00:23:39.476732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### üß† Step 9 ‚Äî Core Logic (Run the Navigator)\n",
    "\n",
    "This function takes the user‚Äôs form inputs, formats them into a profile,  \n",
    "builds the full prompt, and then passes everything into the multi-agent pipeline.  \n",
    "The final consolidated output (summary, opportunities, and 60‚Äì90 day plan)  \n",
    "is returned to the UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b57bf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:39.497211Z",
     "iopub.status.busy": "2025-12-01T00:23:39.496579Z",
     "iopub.status.idle": "2025-12-01T00:23:39.505417Z",
     "shell.execute_reply": "2025-12-01T00:23:39.504401Z"
    },
    "papermill": {
     "duration": 0.017896,
     "end_time": "2025-12-01T00:23:39.507046",
     "exception": false,
     "start_time": "2025-12-01T00:23:39.489150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===== Core function: run AI Opportunity Navigator from UI inputs =====\n",
    "\n",
    "def run_navigator_ui(\n",
    "    name,\n",
    "    background,\n",
    "    skills,\n",
    "    interests,\n",
    "    goals,\n",
    "    graduated,\n",
    "    role_types,\n",
    "    exp_level,\n",
    "    extra_question,\n",
    "):\n",
    "    # Build profile text from the form\n",
    "    profile_text = build_profile_text_ui(\n",
    "        name,\n",
    "        background,\n",
    "        skills,\n",
    "        interests,\n",
    "        goals,\n",
    "        graduated,\n",
    "        role_types,\n",
    "        exp_level,\n",
    "    )\n",
    "\n",
    "    # If user doesn't type a question, use a default one\n",
    "    user_message = extra_question.strip() or \"Give me the best opportunities and a 60‚Äì90 day plan.\"\n",
    "\n",
    "    full_prompt = (\n",
    "        \"You are AI Opportunity Navigator. \"\n",
    "        \"Use the profile below and the user's message to give practical, \"\n",
    "        \"specific suggestions (research roles, internships, projects, and a 60‚Äì90 day plan).\\n\\n\"\n",
    "        \"=== USER PROFILE ===\\n\"\n",
    "        f\"{profile_text}\\n\\n\"\n",
    "        \"=== USER MESSAGE ===\\n\"\n",
    "        f\"{user_message}\\n\"\n",
    "    )\n",
    "\n",
    "    content = UserContent(parts=[Part(text=full_prompt)])\n",
    "\n",
    "    # Call your existing multi-agent pipeline\n",
    "    response_text = \"\"\n",
    "    for event in runner.run(\n",
    "        user_id=session.user_id,\n",
    "        session_id=session.id,\n",
    "        new_message=content,\n",
    "    ):\n",
    "        if getattr(event, \"content\", None):\n",
    "            for p in event.content.parts or []:\n",
    "                if getattr(p, \"text\", None):\n",
    "                    response_text += p.text + \"\\n\\n\"\n",
    "\n",
    "    response_text = response_text.strip() or \"I couldn't generate a response this time.\"\n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eca4dc",
   "metadata": {
    "papermill": {
     "duration": 0.006299,
     "end_time": "2025-12-01T00:23:39.519842",
     "exception": false,
     "start_time": "2025-12-01T00:23:39.513543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2dfdfb7",
   "metadata": {
    "papermill": {
     "duration": 0.006265,
     "end_time": "2025-12-01T00:23:39.532301",
     "exception": false,
     "start_time": "2025-12-01T00:23:39.526036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### üñ•Ô∏è Step 11 ‚Äî Build the Interactive UI (Profile + Chat)\n",
    "\n",
    "This is the final layer of the project ‚Äî a clean Gradio interface that feels like a real product.\n",
    "\n",
    "On the left, the user fills in their background, skills, interests, goals, and experience level.  \n",
    "On the right, they interact with a chat-like interface:\n",
    "\n",
    "- **Start** ‚Üí generates the first personalized summary, matching opportunities, and 60‚Äì90 day plan  \n",
    "- **Follow-up chat** ‚Üí the agent remembers the conversation, asks questions if needed, and adjusts the plan  \n",
    "- **Clear chat** ‚Üí resets the conversation  \n",
    "\n",
    "This UI brings the whole multi-agent workflow to life.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c64c614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:39.547000Z",
     "iopub.status.busy": "2025-12-01T00:23:39.546648Z",
     "iopub.status.idle": "2025-12-01T00:23:42.426563Z",
     "shell.execute_reply": "2025-12-01T00:23:42.425414Z"
    },
    "papermill": {
     "duration": 2.889735,
     "end_time": "2025-12-01T00:23:42.428247",
     "exception": false,
     "start_time": "2025-12-01T00:23:39.538512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1182187368.py:259: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"AI Opportunity Navigator\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://f36cfad26ae59bcae3.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f36cfad26ae59bcae3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== UI: Profile Form + Chat with Start button =====\n",
    "\n",
    "import gradio as gr\n",
    "from google.genai.types import Part, UserContent\n",
    "\n",
    "# Helper: build profile text from form inputs\n",
    "def build_profile_text_ui(\n",
    "    name,\n",
    "    background,\n",
    "    skills,\n",
    "    interests,\n",
    "    goals,\n",
    "    graduated,\n",
    "    role_types,\n",
    "    exp_level,\n",
    "):\n",
    "    name = (name or \"\").strip() or \"User\"\n",
    "    background = (background or \"\").strip()\n",
    "    skills = (skills or \"\").strip()\n",
    "    interests = (interests or \"\").strip()\n",
    "    goals = (goals or \"\").strip()\n",
    "\n",
    "    grad_status = \"Yes\" if graduated else \"No\"\n",
    "    role_types = \", \".join(role_types or []) if role_types else \"Not specified\"\n",
    "\n",
    "    lines = [\n",
    "        f\"Name: {name}\",\n",
    "        f\"Graduation completed: {grad_status}\",\n",
    "        f\"Experience level: {exp_level or 'Not specified'}\",\n",
    "        f\"Target roles: {role_types}\",\n",
    "        \"\",\n",
    "        f\"Background: {background or 'Not provided'}\",\n",
    "        f\"Skills: {skills or 'Not provided'}\",\n",
    "        f\"Interests: {interests or 'Not provided'}\",\n",
    "        f\"Goals: {goals or 'Not provided'}\",\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# Core engine: shared by Start + follow-up chat\n",
    "def run_navigator_core(\n",
    "    user_message,\n",
    "    chat_history,\n",
    "    name,\n",
    "    background,\n",
    "    skills,\n",
    "    interests,\n",
    "    goals,\n",
    "    graduated,\n",
    "    role_types,\n",
    "    exp_level,\n",
    "    is_start=False,\n",
    "):\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "\n",
    "    # Build profile context from the form\n",
    "    profile_text = build_profile_text_ui(\n",
    "        name,\n",
    "        background,\n",
    "        skills,\n",
    "        interests,\n",
    "        goals,\n",
    "        graduated,\n",
    "        role_types,\n",
    "        exp_level,\n",
    "    )\n",
    "\n",
    "    # Turn previous chat history into text\n",
    "    history_text = \"\"\n",
    "    for u, a in chat_history:\n",
    "        history_text += f\"User: {u}\\nAssistant: {a}\\n\\n\"\n",
    "\n",
    "    # If this is the first Start click, we auto-define the user message\n",
    "    if is_start:\n",
    "        user_message = (\n",
    "            \"Use my profile and generate a personalized summary, \"\n",
    "            \"top matching opportunities (RA, internships, projects), \"\n",
    "            \"and a clear 60‚Äì90 day plan. \"\n",
    "            \"If you need more information about me, ask 1‚Äì3 specific questions.\"\n",
    "        )\n",
    "    else:\n",
    "        user_message = (user_message or \"\").strip()\n",
    "        if not user_message:\n",
    "            # no new question, just return old history\n",
    "            return chat_history\n",
    "\n",
    "    # What we send to the orchestrator\n",
    "    full_prompt = (\n",
    "        \"You are AI Opportunity Navigator. \"\n",
    "        \"You know the user's background and goals from the profile below. \"\n",
    "        \"Use that profile and the conversation so far to give practical, \"\n",
    "        \"specific suggestions (research roles, internships, projects, and 60‚Äì90 day plans). \"\n",
    "        \"If you are missing important information, ask direct follow-up questions.\\n\\n\"\n",
    "        \"=== USER PROFILE ===\\n\"\n",
    "        f\"{profile_text}\\n\\n\"\n",
    "        \"=== CONVERSATION SO FAR ===\\n\"\n",
    "        f\"{history_text}\\n\"\n",
    "        \"=== LATEST USER MESSAGE ===\\n\"\n",
    "        f\"{user_message}\\n\"\n",
    "    )\n",
    "\n",
    "    content = UserContent(parts=[Part(text=full_prompt)])\n",
    "\n",
    "    # Run the multi-agent pipeline\n",
    "    assistant_reply = \"\"\n",
    "    for event in runner.run(\n",
    "        user_id=session.user_id,\n",
    "        session_id=session.id,\n",
    "        new_message=content,\n",
    "    ):\n",
    "        if getattr(event, \"content\", None):\n",
    "            for p in event.content.parts or []:\n",
    "                if getattr(p, \"text\", None):\n",
    "                    assistant_reply += p.text + \"\\n\\n\"\n",
    "\n",
    "    assistant_reply = assistant_reply.strip() or \"I couldn't generate a response this time.\"\n",
    "\n",
    "    # Add to chat history (user bubble + assistant bubble)\n",
    "    chat_history = chat_history + [(user_message, assistant_reply)]\n",
    "    return chat_history\n",
    "\n",
    "\n",
    "# Wrapper for Start button\n",
    "def start_conversation(\n",
    "    chat_history,\n",
    "    name,\n",
    "    background,\n",
    "    skills,\n",
    "    interests,\n",
    "    goals,\n",
    "    graduated,\n",
    "    role_types,\n",
    "    exp_level,\n",
    "):\n",
    "    return run_navigator_core(\n",
    "        user_message=\"\",  # will be auto-filled inside\n",
    "        chat_history=chat_history,\n",
    "        name=name,\n",
    "        background=background,\n",
    "        skills=skills,\n",
    "        interests=interests,\n",
    "        goals=goals,\n",
    "        graduated=graduated,\n",
    "        role_types=role_types,\n",
    "        exp_level=exp_level,\n",
    "        is_start=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# Wrapper for follow-up messages\n",
    "def continue_conversation(\n",
    "    message,\n",
    "    chat_history,\n",
    "    name,\n",
    "    background,\n",
    "    skills,\n",
    "    interests,\n",
    "    goals,\n",
    "    graduated,\n",
    "    role_types,\n",
    "    exp_level,\n",
    "):\n",
    "    return run_navigator_core(\n",
    "        user_message=message,\n",
    "        chat_history=chat_history,\n",
    "        name=name,\n",
    "        background=background,\n",
    "        skills=skills,\n",
    "        interests=interests,\n",
    "        goals=goals,\n",
    "        graduated=graduated,\n",
    "        role_types=role_types,\n",
    "        exp_level=exp_level,\n",
    "        is_start=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# ===== Build Gradio UI =====\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # üéØ AI Opportunity Navigator\n",
    "\n",
    "        1. Fill in your profile on the left (once).  \n",
    "        2. Click **Start** to generate your first personalized plan.  \n",
    "        3. Then ask follow-up questions on the right to refine it.  \n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        # -------- LEFT: Profile Form --------\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### 1Ô∏è‚É£ Your Profile\")\n",
    "\n",
    "            name = gr.Textbox(\n",
    "                label=\"Name\",\n",
    "                value=\"Rishindra\",\n",
    "                placeholder=\"Your name\",\n",
    "            )\n",
    "\n",
    "            background = gr.Textbox(\n",
    "                label=\"Background\",\n",
    "                placeholder=\"e.g., MS in CS at Wright State University, focus on AI, cloud, distributed systems‚Ä¶\",\n",
    "                lines=3,\n",
    "            )\n",
    "\n",
    "            skills = gr.Textbox(\n",
    "                label=\"Skills\",\n",
    "                placeholder=\"e.g., Python, ML, DL, PyTorch, Cloud, Networking, Git‚Ä¶\",\n",
    "                lines=3,\n",
    "            )\n",
    "\n",
    "            interests = gr.Textbox(\n",
    "                label=\"Interests\",\n",
    "                placeholder=\"e.g., AI agents, research assistant roles, Kaggle, cloud+AI projects‚Ä¶\",\n",
    "                lines=3,\n",
    "            )\n",
    "\n",
    "            goals = gr.Textbox(\n",
    "                label=\"Goals\",\n",
    "                placeholder=\"e.g., Build strong agentic AI projects, get RA/internship, move towards AI/ML engineer‚Ä¶\",\n",
    "                lines=3,\n",
    "            )\n",
    "\n",
    "            graduated = gr.Checkbox(\n",
    "                label=\"Graduation completed?\",\n",
    "                value=False,\n",
    "            )\n",
    "\n",
    "            role_types = gr.CheckboxGroup(\n",
    "                label=\"What are you mainly looking for?\",\n",
    "                choices=[\n",
    "                    \"Research assistant (RA)\",\n",
    "                    \"Internship\",\n",
    "                    \"Entry-level job\",\n",
    "                    \"Mid-level role\",\n",
    "                    \"Just exploring options\",\n",
    "                ],\n",
    "                value=[\"Research assistant (RA)\", \"Internship\"],\n",
    "            )\n",
    "\n",
    "            exp_level = gr.Radio(\n",
    "                label=\"Experience level\",\n",
    "                choices=[\n",
    "                    \"Student / Fresher\",\n",
    "                    \"0‚Äì1 years industry\",\n",
    "                    \"1‚Äì3 years industry\",\n",
    "                    \"3+ years industry\",\n",
    "                ],\n",
    "                value=\"Student / Fresher\",\n",
    "            )\n",
    "\n",
    "        # -------- RIGHT: Chat Interface --------\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"### 2Ô∏è‚É£ Chat with the AI Opportunity Navigator\")\n",
    "\n",
    "            chatbot = gr.Chatbot(label=\"AI Opportunity Navigator\")\n",
    "\n",
    "            # Start button at top of chat\n",
    "            start_btn = gr.Button(\"üöÄ Start with my profile\")\n",
    "\n",
    "            msg = gr.Textbox(\n",
    "                label=\"Your follow-up message\",\n",
    "                placeholder=\"Ask anything like: 'Focus more on RA roles' or 'Adjust the plan for 30 days only.'\",\n",
    "            )\n",
    "\n",
    "            send_btn = gr.Button(\"Send\")\n",
    "            clear_btn = gr.Button(\"Clear chat\")\n",
    "\n",
    "            # Wire Start button\n",
    "            start_btn.click(\n",
    "                fn=start_conversation,\n",
    "                inputs=[\n",
    "                    chatbot,      # existing chat history\n",
    "                    name,\n",
    "                    background,\n",
    "                    skills,\n",
    "                    interests,\n",
    "                    goals,\n",
    "                    graduated,\n",
    "                    role_types,\n",
    "                    exp_level,\n",
    "                ],\n",
    "                outputs=chatbot,\n",
    "            )\n",
    "\n",
    "            # Wire Send (follow-up messages)\n",
    "            send_btn.click(\n",
    "                fn=continue_conversation,\n",
    "                inputs=[\n",
    "                    msg,\n",
    "                    chatbot,\n",
    "                    name,\n",
    "                    background,\n",
    "                    skills,\n",
    "                    interests,\n",
    "                    goals,\n",
    "                    graduated,\n",
    "                    role_types,\n",
    "                    exp_level,\n",
    "                ],\n",
    "                outputs=chatbot,\n",
    "            ).then(\n",
    "                fn=lambda: \"\",\n",
    "                inputs=None,\n",
    "                outputs=msg,  # clear message box\n",
    "            )\n",
    "\n",
    "            clear_btn.click(\n",
    "                fn=lambda: [],\n",
    "                inputs=None,\n",
    "                outputs=chatbot,\n",
    "            )\n",
    "\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d38e14",
   "metadata": {
    "papermill": {
     "duration": 0.00668,
     "end_time": "2025-12-01T00:23:42.441637",
     "exception": false,
     "start_time": "2025-12-01T00:23:42.434957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b584800a",
   "metadata": {
    "papermill": {
     "duration": 0.006478,
     "end_time": "2025-12-01T00:23:42.454625",
     "exception": false,
     "start_time": "2025-12-01T00:23:42.448147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a000f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T00:23:42.469729Z",
     "iopub.status.busy": "2025-12-01T00:23:42.468874Z",
     "iopub.status.idle": "2025-12-01T00:23:42.473410Z",
     "shell.execute_reply": "2025-12-01T00:23:42.472639Z"
    },
    "papermill": {
     "duration": 0.013668,
     "end_time": "2025-12-01T00:23:42.474853",
     "exception": false,
     "start_time": "2025-12-01T00:23:42.461185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 84.480926,
   "end_time": "2025-12-01T00:23:45.100762",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T00:22:20.619836",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
